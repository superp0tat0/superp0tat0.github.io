---
title: 'How Eigen decomposition affect 2d Gaussian Distribution'
date: 2020-01-30
permalink: /posts/2020/01/BP/
tags:
  - Linear Algebra
  - Probability
---

How eigendecomposition (Spectral decompostion) could help you understand 2d gaussian distribution geometrically?

Introduction
------
I have not realize how powerful eigendecomposition when I first learn about it in my first year linear algebra course. It took about 2 years learning machine learning and probability to find the beauty about eigendecomposition. For example, If you understand what eigenvalues and eigenvectors are, then you will know what Principle Components Analysis (PCA) is doing, why it could reduce the dimensionality of complex datasets and why principle components satisfy independent assumptions.  
I will not talk about eigendecompostion from the very beginning. Instead, I would like to suggest you to take a look of one of favourite youtube channel ["3Blue1Brown"](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw). Their videos are extremely easy to understand, I even suggest my students to watch their videos intend to enhance their understands. Here is the [link if you want to know how eigenvalues and eigenvectors are.](https://www.youtube.com/watch?v=PFDu9oVAE-g&t=551s)

2D Gaussian distribution
------
Now recall a 1D Gaussian distribution, aka Normal distribution. Its' pdf is written as:  
$$P(x) = \frac{1}{{\sigma \sqrt {2\pi } }}e^{{{ - \left( {x - \mu } \right)^2 } \mathord{\left/ {\vphantom {{ - \left( {x - \mu } \right)^2 } {2\sigma ^2 }}} \right. \kern-\nulldelimiterspace} {2\sigma ^2 }}}$$
