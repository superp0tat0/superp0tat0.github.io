---
title: 'How Eigen decomposition affect 2d Gaussian Distribution'
date: 2020-01-30
permalink: /posts/2020/01/BP/
tags:
  - Linear Algebra
  - Probability
---

How eigendecomposition (Spectral decompostion) could help you understand 2d gaussian distribution geometrically?

Introduction
------
I have not realize how powerful eigendecomposition when I first learn about it in my first year linear algebra course. It took about 2 years learning machine learning and probability to find the beauty about eigendecomposition. For example, If you understand what eigenvalues and eigenvectors are, then you will know what Principle Components Analysis (PCA) is doing, why it could reduce the dimensionality of complex datasets and why principle components satisfy independent assumptions.  
I will not talk about eigendecompostion from the very beginning. Instead, I would like to suggest you to take a look of one of favourite youtube channel ["3Blue1Brown"](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw). Their videos are extremely easy to understand, I even suggest my students to watch their videos intend to enhance their understands. Here is the [link if you want to know what eigenvalues and eigenvectors are truly are.](https://www.youtube.com/watch?v=PFDu9oVAE-g&t=551s)

2D Gaussian distribution
------
Now recall a 1D Gaussian distribution, aka Normal distribution. Its' pdf is written as:  
  
$$P(x) = \frac{1}{\sigma \sqrt{2 \pi}}e^{ - ({x - \mu })^2 /2 \sigma ^2 }$$
  
To remind you about the most two important parameters of Gaussian distribution, the $$\mu$$(mean) measures the location of our gaussian distribution and the $$\sigma$$(std error) measures the spread of our distribution. Since both parameters are 1D, aka scalar. It is not hard to understand how they measure our distribution.

![](/post1/1DNormal.png)

However, as we increase the dimension of our $$x$$ to 2. Our 2d Gaussian distribution's pdf is written as:

$$P(x) = \frac{1}{\sqrt{2 \pi} \left | \Sigma \right |^{1/2}}e^{ -\frac{1}{2} ({x - \widetilde{\mu} })^T \Sigma^{-1}  (x- \widetilde{\mu}) }$$

Now our $$\Sigma$$ will be a 2x2 matrix and $$\mu$$ will be a 2x1 vector. It is harder to interpret 2d distribution geometrically. But recall our topic of this context. We could use eigen decomposition to help us.

As you could find the $$\mu$$ only decide where our 2D distribution locate. The shape of our distribution only dependends on $$\Sigma$$. 
